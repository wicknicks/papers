# Papers 

Discovering Context to Prune Large and Complex Search Spaces
------------------------------------------------------------

Conference paper [pdf](https://github.com/wicknicks/papers/blob/master/cuenet-context17-final.pdf), published at [Springer Link](https://link.springer.com/chapter/10.1007/978-3-319-57837-8_7), presented at [Context 17](http://context17.lip6.fr/).

Journal Version [PDF](https://github.com/wicknicks/papers/blob/master/cuenet-openscience18-final.pdf), published at [OpenScience](https://www.openscience.fr/Discovering-Context-for-Real-World-Events). 

Abstract
--------

Specifying the search space is an important step in designing multimedia annotation systems. With the large amount of data available from sensors and web services, context-aware approaches for pruning search spaces are becoming increasingly common. In these approaches, the search space is limited by the contextual information obtained from a fixed set of sources. For example, a system for tagging faces in photos might rely on a static list of candidates obtained from the photo owner’s Facebook profile. These contextual sources can get extremely large, which leads to lower accuracy in the annotation problem.

We present our novel Context Discovery Algorithm, a technique to progressively discover the most relevant search space from a dynamic set of context sources. This allows us to reap the benefits of context, while keeping the size of the search space within bounds.

As a concrete application for our approach, we present a simple photo management application, which tags faces of people in a user’s personal photos. We empirically study the role of CueNet in the face tagging application to tag photos taken at real world events, such as conferences, weddings or social gatherings. Our results show that the availability of event context, and its dynamic discovery, can produce 80% smaller search spaces with nearly 100% correct tags

